---
title: "_Physalia_ population genomics: QC"
format:
  html:
    embed-resources: true
execute:
  echo: false
  warn: false
  error: false
  fig-align: center
theme: cosmo
---

November, 2023

```{r init}
#| include: false
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

library(gridExtra)
library(ggplot2)
library(dplyr)
library(knitr)
library(kableExtra)
library(tidyr)
library(ggtree)
library(ggrepel)
library(maps)
library(gganimate)
library(readr)
library(viridis)

theme_set(theme_classic())
no_legend <- theme(legend.position="none")

```

```{r setup}
metadata <- read.delim("../data/metadata.tsv",header=T,stringsAsFactors=F) %>% filter(status %in% c("sequenced","sequenced elsewhere"))
sample_info <- read.delim("../data/sample_ids.tsv",header=T,stringsAsFactors=F) %>%
  mutate(year = gsub(".*/(.*)","\\1",date_collected), month = as.numeric(gsub("(.*)/.*/.*","\\1",date_collected))) %>% 
  separate(lat_long,into=c("lat","long"),sep=", ")

# should remove YPM-IZ from those that are YPM actually
# or get them accessioned

bam_list <- data.frame(ID = read.table("../QC/angsd_subsample//bam.filelist",head=F) %>% 
  apply(.,1,function(x){gsub(".*sorted/(.*)_pic.bam","\\1",x)})) %>% 
  left_join(.,sample_info,by="ID")

#kable(sample_info) %>%
#  kable_styling(font_size = 16)

locations <- sample_info %>% pull(location) %>% unique()

colors <- c("#E78AC3","#00008B","#800000","#DAA520","#006400","#A6D854","#DC143C","#FC8D62","#452a00","#8DA0CB","#66C2A5","#B3B3B3")
names(colors) <- c("Central Pacific","E Indian","Gulf of California","Gulf of Mexico","NE Atlantic","NW Atlantic","NW Pacific","SE Pacific","SW Atlantic","SW Pacific","W Indian")

ocean_levels <- c("Gulf of Mexico","NW Atlantic","NE Atlantic","SW Atlantic","W Indian","E Indian","SW Pacific","NW Pacific","Central Pacific","Gulf of California","SE Pacific")
sample_info$ocean <- factor(sample_info$ocean,levels=ocean_levels)

pops <- read.delim("../data/pop.txt",sep="\t",header=F)
colnames(pops) <- c("ID","pop")
sample_info <- left_join(sample_info,pops,by="ID")
```     

# Sample quality

## `Kraken2`: cross-species contamination

`Kraken2` attempts to classify reads based on k-mers, against a standard database of known contaminants. `Kraken2` identifies several samples as having a large percentage of "classified" reads. These reads are largely classified as Vibrionales bacteria. Based on these, we will exclude the following samples as potentially highly contaminated:

* YPM-IZ-110432
* YPM-IZ-110973
* YPM-IZ-110632

Sample YPM-IZ-110694-dry was a resequenced sample from dried tissue. For main analyses we will use the other sample, YPM-IZ-110694, and not the dried specimen.

```{r kraken}
#| fig-height: 6

kraken_unclassified <- lapply(metadata$ID,function(x){
  kraken_report <- read.delim(paste0("../QC/kraken/",x,".report.txt"),header=F)
  unclassified <- kraken_report %>% filter(V8 == "unclassified") %>% pull(V1)
  vibrionales <- kraken_report %>% filter(grepl("Vibrionales",V8)) %>% pull(V1)
  return(data.frame(unclassified = unclassified,vibrionales = vibrionales))
})

kraken <- bind_rows(kraken_unclassified) %>% mutate(ID = metadata$ID) %>% 
  left_join(.,sample_info %>% select(ID,ocean),by="ID")

jitter = position_jitter(width=0,seed=123)
kraken_unclass <- ggplot(kraken,aes(label = ID, y = ocean, x = unclassified , color = ocean)) + geom_point(position=jitter) + 
 geom_text_repel(size=2, max.overlaps=10,box.padding=0.2,segment.color=NA,position=jitter)  +
 scale_color_manual(values = colors) + no_legend  +
 xlab("percent reads not classified as contaminant by Kraken2")

kraken_vibrio <- ggplot(kraken,aes(label = ID, y = ocean, x = vibrionales , color = ocean)) + geom_point(position=jitter) + 
   geom_text_repel(size=2, max.overlaps=10,box.padding=0.2,segment.color=NA,position=jitter)  +
 scale_color_manual(values = colors) + no_legend  +
 xlab("percent reads classified as Vibrionales")

grid.arrange(kraken_unclass,kraken_vibrio,nrow=2)
```

## Cross-contamination and duplicated samples

In addition to YPM-IZ-110694-dry, we sequenced a second biological replicat (YPM-IZ-110474-2 of YPM-IZ-110474) and we generated two technical replicates ( YPM-IZ-110269-A and -B of YPM-110269). We used these replicates as quality control for library preparation and sequencing, and as a reference for identifying duplicated samples. 

We assesses similarity by calculating relatedness scores using the King-robust metric in `PLINK2`. Using a cutoff of 0.35 to detect potential duplicate samples, we identify the following pairs:

* YPM-IZ-106941 and YPM-IZ-106944
* YPM-IZ-110878 and YPM-IZ-110879
* YPM-IZ-111013 and YPM-IZ-111015
* YPM-IZ-111018 and YPM-IZ-111019

The latter sample in each pair was subsequently excluded.

We also identified two pairs of samples that had moderately high relatedness (0.07 and 0.13, respectively) with samples from improbably long distances. In both cases, DNA was extracted in the same batch, suggested cross contamination.

* YPM-IZ-110826 (Chile) with sample FM16644 (Canary Islands)
* YPM-IZ-110827 (Chile) with samples YPM-IZ-110878 and YPM-IZ-110879 (Gulf of California).

The former in each pair was subsequently excluded.

No other samples indicated a relatedness above the predicted score for a close relative.

```{r plink}
#| fig-height: 7
#| fig-width: 3
#| fig-align: center


plink <- as.matrix(read.delim("../QC/plink2/plink2.king",sep="\t",header=F))
plink_id <- read.delim("../QC/plink2/plink2.king.id",header=T) %>% rename(ID = X.IID) %>% left_join(.,sample_info,by="ID")
colnames(plink) <- plink_id$ID

plink_long <- plink %>% as.data.frame %>% 
	mutate(ID = plink_id$ID) %>% 
	tidyr::gather(.,key="sample.y",value="relatedness",-ID) %>%
	left_join(.,sample_info,by="ID") %>% rename(sample.x = ID) %>%
  filter(sample.x != sample.y,relatedness > 0) %>% distinct(relatedness,.keep_all=T) %>%
  mutate(combination = paste(sample.x,sample.y,sep=" vs. "))

plink_plot <- ggplot(plink_long,aes(
    y = factor(combination,levels=plink_long %>% arrange(relatedness) %>% pull(combination) %>% unique), 
    x = "",fill = relatedness,label = round(relatedness,3))) + 
  geom_tile() + geom_text(color="white",size=3) +
  scale_fill_viridis(option = "D",limits=c(-0.01,0.5)) + 
  theme(axis.text.y = element_text(size=8)) + 
  no_legend + ylab("comparison")

plink_plot
```

```{r exclude}
excluded_samples <- c(
  "YPM-IZ-110432",
  "YPM-IZ-110973",
  "YPM-IZ-110632",
  "YPM-IZ-106941",
  "YPM-IZ-110878",
  "YPM-IZ-111013",
  "YPM-IZ-111018",
  "YPM-IZ-110826",
  "YPM-IZ-110827"
)
```


## Mapping statistics

We examine sample quality by mapping to our assembled genome. Samples with low mapping percentages indicate potential contamination or low-quality. We can count the number of total reads, reads that map to the reference genome, and reads that are properly paired. From this we can detect a significantly lower mapping percentage for the sample:

* YPM-IZ-110574

Tests using _in silico_ PCR to extract 18S from this sample further indicated contamination from arthropod DNA. This sample will likewise be excluded. 

Comparing statistics on mapped reads vs. properly paired reads shows no significant outliers in terms of quality. 

```{r flagstat}
#| fig-height: 12

flagstat <- lapply(metadata$ID,function(x){
  read.delim(paste0("../QC/flagstat/",x,"_stat.txt"),header=F) %>%
  separate(V1,into=c("reads","category"),sep=" \\+ 0 ") %>%
  mutate(category = gsub(" \\(.*","",category))
  })

flagstat_reads <- data.frame(ID = metadata$ID,
  flag_total = as.numeric(sapply(flagstat,function(x){x %>% filter(category == "in total") %>% pull(reads)})),
  mapped = as.numeric(sapply(flagstat,function(x){x %>% filter(category == "mapped") %>% pull(reads)})),
  properly_paired = as.numeric(sapply(flagstat,function(x){x %>% filter(category == "properly paired") %>% pull(reads)}))) %>%
  left_join(.,sample_info %>% select(ID,ocean,pop),by="ID") %>%
  filter(!ID %in% excluded_samples)


total_mapped <- ggplot(flagstat_reads,aes(label = ID,color = ocean, x = flag_total, y = mapped)) +
   geom_point() + 
   scale_x_log10(labels=  scales::label_number(scale_cut = scales::cut_short_scale())) + 
   scale_y_log10(labels=  scales::label_number(scale_cut = scales::cut_short_scale())) +
   scale_color_manual(values = colors)+
   geom_text_repel(size=2, max.overlaps=10,box.padding=0.1,segment.color=NA)  +
   xlab("total reads") + 
   ylab("mapped") +
   no_legend + 
   coord_fixed()

total_paired <- ggplot(flagstat_reads,aes(label = ID,color = ocean, x = mapped, y = properly_paired))  +
    geom_point() +
   scale_x_log10(labels=  scales::label_number(scale_cut = scales::cut_short_scale())) + 
   scale_y_log10(labels=  scales::label_number(scale_cut = scales::cut_short_scale())) +
   scale_color_manual(values = colors)+
   geom_text_repel(size=2, max.overlaps=10,box.padding=0.1,segment.color=NA)  +
   xlab("mapped") + 
   ylab("properly paired") +
   no_legend + 
   coord_fixed()

grid.arrange(total_mapped,total_paired,nrow=2)

fastqc <- lapply(metadata$ID,function(x){
  path <- paste0("../QC/fastqc/",x,"_R1/")
  f <- list.files(path=path,pattern="fastqc_data.txt",recursive=T)
  fastqc_data <- read.delim(paste0(path,f))
  return(fastqc_data)
})

fastqc_reads <- data.frame(ID = metadata$ID, 
  fastqc_total = as.numeric(sapply(fastqc, function(df) df[df[,1] == "Total Sequences", 2]))) %>%
  left_join(.,flagstat_reads,by="ID") %>%
  filter(!ID %in% excluded_samples)
```


## `FastQC`: GC content

`FastQC` flagged no sequences as having low sequence quality, all were retained. But `FastQC` flagged several samples as having GC contents distinct from the expected distribution. Based on these results we will flag eight samples that fail the GC test and exclude those from our strict analyses (but retain them in general analyses presented in the manuscript).

```{r fastqc}
#| fig-height: 10
#| fig-width: 3
#| fig-align: center

GC <- data.frame(ID = metadata$ID, 
  GC_pass = sapply(fastqc, function(df) df[df[,1] == ">>Per sequence GC content", 2]),
  GC = as.numeric(sapply(fastqc, function(df) df[df[,1] == "%GC", 2]))) %>%
  left_join(.,sample_info %>% select(ID,location,ocean),by="ID") %>% 
  mutate(label = paste0(ID,":",location)) %>% 
  arrange(location,ID) %>%
  filter(!ID %in% excluded_samples)

fastqc_GC <- ggplot(GC,aes(
    y=factor(label,levels=label),
    x=factor(GC_pass,levels=c("pass","warn","fail")),
    fill=GC_pass)) + 
  geom_tile() + 
  xlab("FastQC GC test") + 
  ylab("") +
  no_legend + 
  theme(axis.text = element_text(size = 6))

fastqc_GC
```

# Establishing appropriate filters

## Site quality 

Most sites have high phred quality scores (e.g. a Phred encoded score of 40 indicates a 1 in 10,000 chance of an erroneous call). Based on this, we set the following:

* minimum site quality score = 40

```{r quality}
var_qual <- read_delim("../QC/vcftools_stats/all_filtered_subsample.lqual", delim = "\t",
           col_names = c("chr", "pos", "qual"), skip = 1)

quality <- ggplot(var_qual, aes(qual))  +  geom_vline(xintercept=40,linetype="dotted") +
  geom_histogram(fill="gray",bins=50)  +
  scale_x_continuous(breaks = c(0,10,20,30,40,50,100,150,200,250)) + 
  xlab("Phred-scaled quality score") 

quality
```

## Coverage

We can estimate coverage by dividing the number of basepairs sequenced for each sample by the length of the reference genome, 3.3Gb. Samples were sequenced to variable depths, with estimated coverage ranging from 5-60x.

Samples with greater than 20x target coverage (dashed line) were considered high coverage, and were selected for genome size estimation and other high-coverage analyses.

```{r reads}
#| fig.height = 9
high_cov <- 20

genome_length <- 3300000000
read_length <- 150

total_coverage <- ggplot(flagstat_reads,aes(label = ID, y = ocean, x = flag_total , color = ocean)) + 
  geom_point(position=jitter) + 
   geom_text_repel(size=2, max.overlaps=5,box.padding=0.1,segment.color=NA,position=jitter)  +
 scale_color_manual(values = colors) + no_legend  +
 scale_x_continuous(
    labels=  scales::label_number(scale_cut = scales::cut_short_scale()),
    breaks = c(0, 100, 1000, 10000) * 1e6,
    sec.axis = sec_axis(trans = ~ . *read_length / genome_length, name = "estimated coverage against 3.3Gb genome",breaks=c(0,1,2,3,4,5,10,25,50,100))
  ) + 
  geom_vline(xintercept=((high_cov * genome_length) / read_length),linetype="dashed") +
 xlab("total reads")

paired_coverage <- ggplot(flagstat_reads,aes(label = ID, y = ocean, x = properly_paired , color = ocean)) + 
  geom_point(position=jitter) + 
   geom_text_repel(size=2, max.overlaps=5,box.padding=0.1,segment.color=NA,position=jitter)  +
 scale_color_manual(values = colors) + no_legend  +
 scale_x_continuous(
    labels=  scales::label_number(scale_cut = scales::cut_short_scale()),
    breaks = c(0, 100, 1000, 10000) * 1e6,
    sec.axis = sec_axis(trans = ~ . *read_length / genome_length, name = "estimated coverage against 3.3Gb genome",breaks=c(0,1,2,3,4,5,10,25,50,100))
  ) + 
  geom_vline(xintercept=((high_cov * genome_length) / read_length),linetype="dashed") +
 xlab("properly paired reads")

grid.arrange(total_coverage,paired_coverage)
```

We use `angsd` to estimate realized depth across samples and sites using a subset of genomic regions. We categorize samples into those with poor coverage distributions, those with low coverage (between 2 and 10x), moderate coverage (11 and 20x) and high coverage (>20x). Poor coverage samples were the following:

* KM5633
* KM5634
* KM5635
* KM5636
* YPM-IZ-110277
* YPM-IZ-110268

```{r depth}
#| fig-height: 12

depth_sample <- read.delim("../QC/angsd_subsample/subsample.depthSample",header=F)
 colnames(depth_sample) <- seq(0,101)
 ds <- depth_sample %>% select(-c(`101`)) %>% 
   mutate(ID=bam_list$ID,
     location=bam_list$location,
     ocean=bam_list$ocean) %>% 
   tidyr::pivot_longer(cols=-c(ID,location,ocean),names_to="reads") %>%
   mutate(reads = as.numeric(reads))
 
ds_peak_5 <- ds %>% group_by(ID) %>% filter(reads > 4, reads < 100) %>% filter(value == max(value))
ds_peak_2 <- ds %>% filter(ID %in% (ds_peak_5 %>% filter(reads == 5) %>% pull(ID))) %>% 
  group_by(ID) %>% filter(reads > 1, reads < 100) %>% filter(value == max(value))
ds_peak_sub <- ds %>% filter(ID %in% (ds_peak_2 %>% filter(reads == 2) %>% pull(ID))) %>% 
  group_by(ID) %>% filter(reads > 0, reads < 100) %>% filter(value == max(value))
ds_peak <- bind_rows(ds_peak_5,ds_peak_2,ds_peak_sub) %>% group_by(ID) %>% arrange(reads) %>% slice(1L)
 
breaks <- c(1,2,3,4,5,10,20,30,40,50,60,70,80,90,100)

poor_cov <- ds_peak %>% filter(reads < 2) %>% pull(ID)
low_cov <- ds_peak %>% filter(reads >=2, reads < 10) %>% pull(ID)
med_cov <- ds_peak %>% filter(reads >=11, reads < 20) %>% pull(ID)
hi_cov <- ds_peak %>% filter(reads >=20) %>% pull(ID)

g1 <- ggplot(ds %>% filter(ID %in% poor_cov),aes(label=ID,x=reads,y=value,color=ocean,group=ID)) + 
     geom_line() +  scale_x_continuous(breaks =breaks) +
     scale_color_manual(values = colors) + no_legend + 
     ggtitle("poor coverage distribution") +
     xlab("read depth") + ylab("number of sites") +
    geom_text_repel(data = ds_peak %>% filter(ID %in% poor_cov),aes(x = reads, y = value),nudge_x=12,nudge_y=50000,size=2, max.overlaps=100,box.padding=0.1,segment.color=NA)


g2 <- ggplot(ds %>% filter(ID %in% low_cov),aes(label=ID,x=reads,y=value,color=ocean,group=ID)) + 
     geom_vline(data = ds_peak %>% filter(ID %in% low_cov),aes(xintercept = reads,color = ocean), linetype="dotted") +
     geom_line() +  scale_x_continuous(breaks = breaks) +
     scale_color_manual(values = colors) + no_legend +
     xlab("read depth") + ylab("number of sites") +
     ggtitle("coverage between 2x and 10x") 

g3 <- ggplot(ds %>% filter(ID %in% med_cov),aes(label=ID,x=reads,y=value,color=ocean,group=ID)) + 
     geom_vline(data = ds_peak %>% filter(ID %in% med_cov),aes(xintercept = reads,color = ocean), linetype="dotted") +
     geom_line() +  scale_x_continuous(breaks = breaks) +
     scale_color_manual(values = colors) + no_legend +
     xlab("read depth") + ylab("number of sites") +
     ggtitle("coverage between 11x and 20x") 

g4 <- ggplot(ds %>% filter(ID %in% hi_cov),aes(label=ID,x=reads,y=value,color=ocean,group=ID)) + 
     geom_vline(data = ds_peak %>% filter(ID %in% hi_cov),aes(xintercept = reads,color = ocean), linetype="dotted") +
     geom_line() +  scale_x_continuous(breaks = breaks) +
     scale_color_manual(values = colors) + no_legend +
     xlab("read depth") + ylab("number of sites") +
     ggtitle("coverage >20x") +
     geom_text_repel(data = ds_peak %>% filter(ID %in% hi_cov),aes(x = reads, y = value),nudge_y=50000,size=2, max.overlaps=10,box.padding=0.1,segment.color=NA)

 
grid.arrange(g1,g2,g3,g4,nrow=4)
```

From the previous distributions we calculated peak depth, and then compared to total reads. We observed that GC distribution, as assessed using `FastQC` impact the relationship between input reads and realized depth. 

To address this, we run an additional robustness test using only samples that pass the GC test.

```{r reads_depth}
#| fig.height = 4.5 

 reads_ds <- left_join(flagstat_reads,ds_peak %>% select(ID,reads,value),by="ID") %>%
   left_join(.,GC %>% select(ID,GC_pass),by="ID")

reads_vs_depth_GC <- ggplot(reads_ds,aes(label = ID, x = flag_total, y = reads, color = GC_pass)) + 
   geom_point() + 
       xlab("total reads") + ylab("peak depth")  +
   geom_text_repel(size=2, max.overlaps=10,box.padding=0.1,segment.color=NA) 

reads_vs_depth_GC
```


We used realized depth to establish the cutoff for minimum and maximum depth across sites.

 For `ANGSD` analyses that are robust to low coverage, we did not perform any filtering based on depth, but for `BCF` based analsyes (e.g Fst calculations), we set the following filters across sites for each sample:

* minimum depth = 2x
* maximum depth = 99x

```{r peak}
depth_distributions <- ggplot(ds,aes(x=reads,y=value,color=ocean,group=ID)) + 
     geom_line() +  scale_x_continuous(breaks = breaks) +
     xlab("realized depth") + ylab("number of sites") +
     scale_color_manual(values = colors) + 
     geom_vline(xintercept=2,linetype="dotted") +
     geom_vline(xintercept=99,linetype="dotted") + 
     no_legend

depth_distributions
```

## Missingness 

We examined the proportion of missing sites across samples. This was calculated using `vcftools` on a random subsample of sites from across genome regions. From this we can see identify several samples with a high proportion of missing sites, in particular:

* KM5634

```{r missing-ind}
ind_miss  <- read_delim("../QC/vcftools_stats/all_filtered_subsample.imiss", delim = "\t",
                        col_names = c("ID", "ndata", "nfiltered", "nmiss", "fmiss"), skip = 1)  %>% 
           left_join(sample_info,by="ID") 


missingness_sample <- ggplot(ind_miss, aes(label = ID, y = ocean, x = fmiss,color=ocean)) + 
  geom_point(position=jitter) + 
  geom_text_repel(size=2, max.overlaps=10,box.padding=0.1,segment.color=NA,position=jitter)  +
  scale_color_manual(values = colors) +
      xlab("proportion missing data") + ylab("ocean") +
    scale_x_continuous(breaks=c(0,0.25,0.5,0.75,1),limits = c(0,1)) + 
    no_legend
missingness_sample
```

We can use the distribution of missing samples across sites to establish an appropriate filter for missingness. Here we set the following:

* tolerate missingness equal to or below 75%

This means we exclude sites for which >25% of samples are missing data.

```{r missing-var}
var_miss <- read_delim("../QC/vcftools_stats/all_filtered_subsample.lmiss", delim = "\t",
                       col_names = c("chr", "pos", "nchr", "nfiltered", "nmiss", "fmiss"), skip = 1)

missingness_site <- ggplot(var_miss, aes(fmiss)) + 
  geom_vline(xintercept=0.25,linetype="dotted") +
  geom_histogram(fill="gray",bins=98)  +
      xlab("fraction of individuals missing data") + ylab("number of sites") +
    ggtitle("missingness across sites")

missingness_site
```




